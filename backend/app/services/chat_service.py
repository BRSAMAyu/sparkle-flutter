"""
å¯¹è¯æœåŠ¡
Chat Service - ç®¡ç†ç”¨æˆ·å¯¹è¯å’Œ LLM äº¤äº’
"""
import json
import uuid
from typing import AsyncGenerator, Optional, Dict, Any
from uuid import UUID
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from loguru import logger
from datetime import datetime

from app.models.chat import ChatMessage, MessageRole
from app.models.user import User
from app.services.llm.parser import LLMResponseParser, LLMResponse

class ChatService:
    def __init__(self):
        self.parser = LLMResponseParser()
    
    async def stream_chat(
        self,
        db: AsyncSession,
        user_id: UUID,
        content: str,
        session_id: Optional[UUID] = None,
        task_id: Optional[UUID] = None,
        message_id: Optional[str] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¯¹è¯æ ¸å¿ƒé€»è¾‘
        """
        if not session_id:
            session_id = uuid.uuid4()
            
        # 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ (å¦‚æœæœ‰ message_idï¼Œéœ€æ£€æŸ¥å¹‚ç­‰ï¼Œä½†é€šå¸¸ç”±ä¸­é—´ä»¶å¤„ç†è¯·æ±‚çº§å¹‚ç­‰)
        # è¿™é‡Œæˆ‘ä»¬åªæ˜¯ä¿å­˜è®°å½•
        user_message = ChatMessage(
            user_id=user_id,
            session_id=session_id,
            task_id=task_id,
            role=MessageRole.USER,
            content=content,
            message_id=message_id or str(uuid.uuid4())
        )
        db.add(user_message)
        await db.commit()
        
        # 2. è°ƒç”¨ LLM (æ¨¡æ‹Ÿæµå¼è¾“å‡º)
        # TODO: é›†æˆçœŸå®çš„ LLM Service (OpenAI/Qwen)
        full_response_text = ""
        
        # æ¨¡æ‹Ÿ LLM è¾“å‡º "ä½ å¥½"
        mock_chunks = ["æˆ‘", "æ˜¯", "Sparkle", "ï¼Œ", "å¾ˆ", "é«˜", "å…´", "ä¸º", "ä½ ", "æœ", "åŠ¡", "ã€‚"]
        
        for chunk in mock_chunks:
            full_response_text += chunk
            yield {
                "event": "token",
                "data": json.dumps({"content": chunk})
            }
            # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            await asyncio.sleep(0.05)
            
        # 3. è§£æå“åº” (å°è¯•è§£æ Actions)
        # è¿™é‡Œæ¨¡æ‹Ÿä¸€ä¸ªé JSON å“åº”ï¼Œè§¦å‘é™çº§æˆ–æ­£å¸¸æ–‡æœ¬
        # å¦‚æœ content åŒ…å« JSONï¼Œåˆ™è§£æ
        
        llm_response = self.parser.parse(full_response_text)
        
        # 4. å¤„ç†è§£æç»“æœ
        if llm_response.parse_degraded:
            # ğŸ†• v2.1: æ¨é€é™çº§çŠ¶æ€
            yield {
                "event": "parse_status",
                "data": json.dumps({
                    "degraded": True,
                    "reason": llm_response.degraded_reason
                })
            }
        elif llm_response.actions:
            # æ¨é€ Actions
            yield {
                "event": "actions",
                "data": json.dumps({
                    "actions": [action.model_dump() for action in llm_response.actions]
                })
            }
            # TODO: å¼‚æ­¥æ‰§è¡Œ Actions (JobService)
            
        # 5. ä¿å­˜ Assistant æ¶ˆæ¯
        assistant_message = ChatMessage(
            user_id=user_id,
            session_id=session_id,
            task_id=task_id,
            role=MessageRole.ASSISTANT,
            content=llm_response.assistant_message,
            actions=[a.model_dump() for a in llm_response.actions] if llm_response.actions else None,
            parse_degraded=llm_response.parse_degraded
        )
        db.add(assistant_message)
        await db.commit()
        
        # 6. ç»“æŸ
        yield {
            "event": "done",
            "data": json.dumps({
                "message_id": str(assistant_message.id),
                "session_id": str(session_id)
            })
        }

# å¯¼å‡ºå•ä¾‹
chat_service = ChatService()
